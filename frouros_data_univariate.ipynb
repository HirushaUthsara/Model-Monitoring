{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from sklearn.datasets import make_classification\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "from frouros.detectors.data_drift import KSTest"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Kolmogorov-Smirnov test univariate detector with a synthetic dataset composed by 3 informative features and 2 non-informative/useless features for the model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "np.random.seed(seed=31)\n",
                "\n",
                "X, y = make_classification(\n",
                "    n_samples=10000,\n",
                "    n_features=5,\n",
                "    n_informative=3,\n",
                "    n_redundant=0,\n",
                "    n_repeated=0,\n",
                "    n_classes=2,\n",
                "    scale=[10, 0.1, 5, 15, 1],\n",
                "    shuffle=False,  # False because it also shuffles features order (we dont want features to be shuffled)\n",
                "    random_state=31,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "idxs = np.arange(X.shape[0])\n",
                "np.random.shuffle(idxs)\n",
                "X, y = X[idxs], y[idxs]\n",
                "\n",
                "idx_split = int(X.shape[0] * 0.7)\n",
                "X_train, y_train, X_test, y_test = X[:idx_split], y[:idx_split], X[idx_split:], y[idx_split:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "alpha = 0.01"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Create and fit a Kolmogorov-Smirnov test detector for each feature using the training dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "collapsed": false
            },
            "outputs": [],
            "source": [
                "detectors = []\n",
                "for i in range(X_train.shape[1]):\n",
                "    detector = KSTest()\n",
                "    _ = detector.fit(X=X_train[:, i])\n",
                "    detectors.append(detector)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "Fitting a decision tree with the training/reference dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "collapsed": false
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=31)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=31)</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "DecisionTreeClassifier(random_state=31)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = DecisionTreeClassifier(random_state=31)\n",
                "model.fit(X=X_train, y=y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "In addition to obtaining the predictions for the test data by calling the predict method, the detector compares the reference data with test data to determine if drift is occurring for each feature."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "collapsed": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature 1:\n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "ks_2samp() got an unexpected keyword argument 'method'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21100\\1753956869.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Feature {i+1}:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\tp-value: {round(p_value, 4)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mc:\\Users\\hirushau\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\frouros\\detectors\\data_drift\\batch\\base.py\u001b[0m in \u001b[0;36mcompare\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             )\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             callback.on_compare_end(  # type: ignore\n",
                        "\u001b[1;32mc:\\Users\\hirushau\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\frouros\\detectors\\data_drift\\batch\\statistical_test\\base.py\u001b[0m in \u001b[0;36m_compare\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_common_checks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: N806\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_specific_checks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa: N806\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mc:\\Users\\hirushau\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\frouros\\detectors\\data_drift\\batch\\base.py\u001b[0m in \u001b[0;36m_get_result\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     ) -> Union[List[float], List[Tuple[float, float]], Tuple[float, float]]:\n\u001b[1;32m--> 120\u001b[1;33m         result = self._apply_method(  # type: ignore # pylint: disable=not-callable\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0mX_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mc:\\Users\\hirushau\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\frouros\\detectors\\data_drift\\batch\\statistical_test\\base.py\u001b[0m in \u001b[0;36m_apply_method\u001b[1;34m(self, X_ref, X, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     ) -> Tuple[float, float]:\n\u001b[1;32m---> 23\u001b[1;33m         statistical_test = self._statistical_test(\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mX_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;32mc:\\Users\\hirushau\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\frouros\\detectors\\data_drift\\batch\\statistical_test\\ks.py\u001b[0m in \u001b[0;36m_statistical_test\u001b[1;34m(X_ref, X, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     ) -> StatisticalResult:\n\u001b[1;32m---> 60\u001b[1;33m         test = ks_2samp(\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mdata1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mdata2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
                        "\u001b[1;31mTypeError\u001b[0m: ks_2samp() got an unexpected keyword argument 'method'"
                    ]
                }
            ],
            "source": [
                "y_pred = model.predict(X=X_test)\n",
                "for i, detector in enumerate(detectors):\n",
                "    print(f\"Feature {i+1}:\")\n",
                "    p_value = detector.compare(X=X_test[:, i])[0].p_value\n",
                "    print(f\"\\tp-value: {round(p_value, 4)}\")\n",
                "    if p_value <= alpha:\n",
                "        print(\"\\tData drift detected\\n\")\n",
                "    else:\n",
                "        print(\"\\tNo data drift detected\\n\")\n",
                "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 4)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "#####Noise on informative features\n",
                "simulate how data drift can end up degrading model's performance, we apply some noise to two of the three relevant features, as shown below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature 0:\n",
                        "\tp-value: 0.0\n",
                        "\tData drift detected\n",
                        "\n",
                        "Feature 1:\n",
                        "\tp-value: 0.0\n",
                        "\tData drift detected\n",
                        "\n",
                        "Feature 2:\n",
                        "\tp-value: 0.0637\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Feature 3:\n",
                        "\tp-value: 0.2359\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Feature 4:\n",
                        "\tp-value: 0.8064\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Accuracy: 0.6353\n"
                    ]
                }
            ],
            "source": [
                "X_test_noise = X_test.copy()\n",
                "X_test_noise[:, :2] = X_test_noise[:, :2] + np.random.normal(loc=0, scale=X_test_noise[:, :2].std(axis=0), size=X_test_noise[:, :2].shape)  # Add noise to features 1 and 2 (both informative)\n",
                "y_pred = model.predict(X=X_test_noise)\n",
                "for i, detector in enumerate(detectors):\n",
                "    print(f\"Feature {i}:\")\n",
                "    p_value = detector.compare(X=X_test_noise[:, i])[0].p_value\n",
                "    print(f\"\\tp-value: {round(p_value, 4)}\")\n",
                "    if p_value <= alpha:\n",
                "        print(\"\\tData drift detected\\n\")\n",
                "    else:\n",
                "        print(\"\\tNo data drift detected\\n\")\n",
                "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 4)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false
            },
            "source": [
                "## Noise on non-informative features\n",
                "\n",
                "On the other hand, if we apply some noise to the non-informative features (they should not be important for the model) we expect to see data drift in these features, but model's performance should not decrease significantly, meaning that features affected by the noise are completely irrelevant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature 0:\n",
                        "\tp-value: 0.1606\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Feature 1:\n",
                        "\tp-value: 0.5984\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Feature 2:\n",
                        "\tp-value: 0.0637\n",
                        "\tNo data drift detected\n",
                        "\n",
                        "Feature 3:\n",
                        "\tp-value: 0.0\n",
                        "\tData drift detected\n",
                        "\n",
                        "Feature 4:\n",
                        "\tp-value: 0.0\n",
                        "\tData drift detected\n",
                        "\n",
                        "Accuracy: 0.928\n"
                    ]
                }
            ],
            "source": [
                "X_test_noise = X_test.copy()\n",
                "X_test_noise[:, 3:] = X_test_noise[:, 3:] + np.random.normal(loc=0, scale=X_test_noise[:, 3:].std(axis=0), size=X_test_noise[:, 3:].shape)  # Add noise to features 4 and 5 (both non-informative)\n",
                "y_pred = model.predict(X=X_test_noise)\n",
                "for i, detector in enumerate(detectors):\n",
                "    print(f\"Feature {i}:\")\n",
                "    p_value = detector.compare(X=X_test_noise[:, i])[0].p_value\n",
                "    print(f\"\\tp-value: {round(p_value, 4)}\")\n",
                "    if p_value <= alpha:\n",
                "        print(\"\\tData drift detected\\n\")\n",
                "    else:\n",
                "        print(\"\\tNo data drift detected\\n\")\n",
                "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 4)}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
